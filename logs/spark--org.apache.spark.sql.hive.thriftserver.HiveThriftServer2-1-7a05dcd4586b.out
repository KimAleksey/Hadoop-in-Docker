Spark Command: /opt/java/openjdk/bin/java -cp /opt/spark/conf:/opt/spark/jars/* -Xmx1g -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false org.apache.spark.deploy.SparkSubmit --master spark://spark-master:7077 --conf spark.sql.warehouse.dir=hdfs://namenode:9000/user/hive/warehouse --class org.apache.spark.sql.hive.thriftserver.HiveThriftServer2 --name Thrift JDBC/ODBC Server spark-internal --hiveconf hive.server2.thrift.port=10000 --hiveconf hive.server2.thrift.bind.host=0.0.0.0
========================================
26/02/08 21:25:29 INFO HiveThriftServer2: Started daemon with process name: 13@7a05dcd4586b
26/02/08 21:25:29 INFO SignalUtils: Registering signal handler for TERM
26/02/08 21:25:29 INFO SignalUtils: Registering signal handler for HUP
26/02/08 21:25:29 INFO SignalUtils: Registering signal handler for INT
26/02/08 21:25:29 INFO HiveThriftServer2: Starting SparkContext
26/02/08 21:25:29 INFO HiveConf: Found configuration file null
26/02/08 21:25:29 INFO SparkContext: Running Spark version 3.5.0
26/02/08 21:25:29 INFO SparkContext: OS info Linux, 6.10.14-linuxkit, aarch64
26/02/08 21:25:29 INFO SparkContext: Java version 11.0.20.1
26/02/08 21:25:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
26/02/08 21:25:29 INFO ResourceUtils: ==============================================================
26/02/08 21:25:29 INFO ResourceUtils: No custom resources configured for spark.driver.
26/02/08 21:25:29 INFO ResourceUtils: ==============================================================
26/02/08 21:25:29 INFO SparkContext: Submitted application: Thrift JDBC/ODBC Server
26/02/08 21:25:29 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
26/02/08 21:25:29 INFO ResourceProfile: Limiting resource is cpu
26/02/08 21:25:29 INFO ResourceProfileManager: Added ResourceProfile id: 0
26/02/08 21:25:29 INFO SecurityManager: Changing view acls to: spark
26/02/08 21:25:29 INFO SecurityManager: Changing modify acls to: spark
26/02/08 21:25:29 INFO SecurityManager: Changing view acls groups to: 
26/02/08 21:25:29 INFO SecurityManager: Changing modify acls groups to: 
26/02/08 21:25:29 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: spark; groups with view permissions: EMPTY; users with modify permissions: spark; groups with modify permissions: EMPTY
26/02/08 21:25:29 INFO Utils: Successfully started service 'sparkDriver' on port 46045.
26/02/08 21:25:29 INFO SparkEnv: Registering MapOutputTracker
26/02/08 21:25:29 INFO SparkEnv: Registering BlockManagerMaster
26/02/08 21:25:29 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
26/02/08 21:25:29 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
26/02/08 21:25:29 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
26/02/08 21:25:29 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-202ee257-8a3a-4a02-9317-36c20a97a474
26/02/08 21:25:29 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
26/02/08 21:25:29 INFO SparkEnv: Registering OutputCommitCoordinator
26/02/08 21:25:29 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
26/02/08 21:25:29 INFO Utils: Successfully started service 'SparkUI' on port 4040.
26/02/08 21:25:29 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://spark-master:7077...
26/02/08 21:25:29 INFO TransportClientFactory: Successfully created connection to spark-master/172.19.0.4:7077 after 11 ms (0 ms spent in bootstraps)
26/02/08 21:25:30 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20260208212530-0000
26/02/08 21:25:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 40513.
26/02/08 21:25:30 INFO NettyBlockTransferService: Server created on 7a05dcd4586b:40513
26/02/08 21:25:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
