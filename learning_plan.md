# –ü–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è Hadoop –∏ Spark üêò‚ö°Ô∏è

–≠—Ç–æ—Ç –ø–ª–∞–Ω —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –≤–∞—à–µ–º —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç–æ–º Docker-–æ–∫—Ä—É–∂–µ–Ω–∏–∏. –ú—ã –Ω–∞—á–Ω–µ–º —Å –æ—Å–Ω–æ–≤ –∏ –±—É–¥–µ–º –¥–≤–∏–≥–∞—Ç—å—Å—è –∫ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–º –∫–æ–Ω—Ü–µ–ø—Ü–∏—è–º.

## –ú–æ–¥—É–ª—å 1: –û—Å–Ω–æ–≤—ã HDFS (Hadoop Distributed File System)
**–¶–µ–ª—å:** –ù–∞—É—á–∏—Ç—å—Å—è —É–ø—Ä–∞–≤–ª—è—Ç—å —Ñ–∞–π–ª–æ–≤–æ–π —Å–∏—Å—Ç–µ–º–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∞.

1.  **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ HDFS**:
    *   NameNode vs DataNode (–ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –≤ UI: http://localhost:9870).
    *   –ë–ª–æ–∫–∏, —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—è (–ø–æ—á–µ–º—É —Ñ–∞–π–ª—ã —Ä–∞–∑–±–∏–≤–∞—é—Ç—Å—è –Ω–∞ —á–∞—Å—Ç–∏).
2.  **–ü—Ä–∞–∫—Ç–∏–∫–∞ (CLI –ö–æ–º–∞–Ω–¥—ã)**:
    *   `hdfs dfs -ls /` (–ü—Ä–æ—Å–º–æ—Ç—Ä)
    *   `hdfs dfs -mkdir /user/myname` (–°–æ–∑–¥–∞–Ω–∏–µ –ø–∞–ø–æ–∫)
    *   `hdfs dfs -put localfile.txt /user/myname/` (–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö)
    *   `hdfs dfs -cat /user/myname/localfile.txt` (–ß—Ç–µ–Ω–∏–µ)
    *   `hdfs dfs -rm /user/myname/localfile.txt` (–£–¥–∞–ª–µ–Ω–∏–µ)

## –ú–æ–¥—É–ª—å 2: MapReduce –∏ YARN
**–¶–µ–ª—å:** –ü–æ–Ω—è—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏.

1.  **–ö–æ–Ω—Ü–µ–ø—Ü–∏—è MapReduce**:
    *   Map (–§–∏–ª—å—Ç—Ä–∞—Ü–∏—è/–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞) -> Shuffle -> Reduce (–ê–≥—Ä–µ–≥–∞—Ü–∏—è).
2.  **YARN (Yet Another Resource Negotiator)**:
    *   ResourceManager (Master) –∏ NodeManager (Worker).
    *   –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ UI: http://localhost:8088.
3.  **–ü—Ä–∞–∫—Ç–∏–∫–∞**:
    *   –ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ **WordCount** –Ω–∞ Hadoop Streaming (Python) –∏–ª–∏ Java.
    *   –ù–∞–±–ª—é–¥–µ–Ω–∏–µ –∑–∞ –∑–∞–¥–∞—á–µ–π –≤ YARN UI.

## –ú–æ–¥—É–ª—å 3: Spark Core –∏ RDD
**–¶–µ–ª—å:** –ü–µ—Ä–µ–π—Ç–∏ –∫ —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–º –±—ã—Å—Ç—Ä—ã–º –≤—ã—á–∏—Å–ª–µ–Ω–∏—è–º –≤ –ø–∞–º—è—Ç–∏.

1.  **–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Spark**:
    *   Driver, Master, Worker, Executor.
    *   UI: http://localhost:8090.
2.  **RDD (Resilient Distributed Dataset)**:
    *   –ù–µ–∏–∑–º–µ–Ω—è–µ–º—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤.
    *   Transformations (map, filter) vs Actions (count, collect).
    *   Lazy evaluation (–ª–µ–Ω–∏–≤—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è).
3.  **–ü—Ä–∞–∫—Ç–∏–∫–∞ (Spark Shell)**:
    *   –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è —Ä–∞–±–æ—Ç–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –≤ `spark-shell`.
    *   –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞ –∏–∑ HDFS –≤ RDD.

## –ú–æ–¥—É–ª—å 4: Spark SQL –∏ DataFrames
**–¶–µ–ª—å:** –†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–∫–∞–∫ –≤ Pandas –∏–ª–∏ SQL).

1.  **TDataFrame / Dataset**:
    *   –°—Ö–æ–∂–µ—Å—Ç—å —Å —Ç–∞–±–ª–∏—Ü–∞–º–∏ —Ä–µ–ª—è—Ü–∏–æ–Ω–Ω—ã—Ö –ë–î.
    *   –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä Catalyst.
2.  **Spark SQL**:
    *   –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ SQL-–∑–∞–ø—Ä–æ—Å–æ–≤ –Ω–∞–¥ –¥–∞–Ω–Ω—ã–º–∏.
    *   –ß—Ç–µ–Ω–∏–µ/–∑–∞–ø–∏—Å—å JSON, CSV, Parquet.
3.  **–ü—Ä–∞–∫—Ç–∏–∫–∞**:
    *   –ó–∞–≥—Ä—É–∑–∫–∞ CSV –≤ DataFrame.
    *   –ê–≥—Ä–µ–≥–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö (groupBy, count).
    *   –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—Ä–∞—Ç–Ω–æ –≤ HDFS.

## –ú–æ–¥—É–ª—å 5: –ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–µ —Ç–µ–º—ã (–ø–æ –∂–µ–ª–∞–Ω–∏—é)
1.  **Hive**: SQL-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –ø–æ–≤–µ—Ä—Ö HDFS (–º–æ–∂–Ω–æ —Ä–∞–∑–≤–µ—Ä–Ω—É—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ).
2.  **Spark Streaming**: –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.

---

### üöÄ –ü–µ—Ä–≤—ã–π —à–∞–≥: –ü—Ä–∞–∫—Ç–∏–∫–∞ HDFS
–î–∞–≤–∞–π—Ç–µ –Ω–∞—á–Ω–µ–º —Å –ú–æ–¥—É–ª—è 1. –í–∞—à–µ –ø–µ—Ä–≤–æ–µ –∑–∞–¥–∞–Ω–∏–µ:
1.  –ó–∞–π—Ç–∏ –≤ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä `namenode`.
2.  –°–æ–∑–¥–∞—Ç—å —Å–≤–æ—é –¥–æ–º–∞—à–Ω—é—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –≤ HDFS.
3.  –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ç—É–¥–∞ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª.
4.  –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ —Ñ–∞–π–ª –ø–æ—è–≤–∏–ª—Å—è –≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ (http://localhost:9870).

–ì–æ—Ç–æ–≤—ã –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å?
