# üéì –ü–ª–∞–Ω –∏–∑—É—á–µ–Ω–∏—è Big Data (Hadoop & Spark)

–≠—Ç–æ—Ç –ø–ª–∞–Ω –æ–±—É—á–µ–Ω–∏—è –±—ã–ª –≤—ã–ø–æ–ª–Ω–µ–Ω –≤–∞–º–∏ –¥–ª—è –æ—Å–≤–æ–µ–Ω–∏—è –æ—Å–Ω–æ–≤ —Ä–∞–±–æ—Ç—ã —Å –∫–ª–∞—Å—Ç–µ—Ä–æ–º Hadoop –≤ Docker. –û–Ω –≤–∫–ª—é—á–∞–µ—Ç –∫–∞–∫ —Ç–µ–æ—Ä–∏—é, —Ç–∞–∫ –∏ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω—ã–µ —Ä–∞–±–æ—Ç—ã (Labs), –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —É–∂–µ –∑–∞–≤–µ—Ä—à–∏–ª–∏ –∏–ª–∏ –º–æ–∂–µ—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å.

## ‚úÖ –ú–æ–¥—É–ª—å 1: –û—Å–Ω–æ–≤—ã HDFS (Hadoop Distributed File System)
**–¶–µ–ª—å:** –ù–∞—É—á–∏—Ç—å—Å—è —É–ø—Ä–∞–≤–ª—è—Ç—å —Ñ–∞–π–ª–∞–º–∏ –≤ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º–µ.

### üìö –¢–µ–æ—Ä–∏—è
- –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ NameNode (Master) –∏ DataNode (Worker).
- –ë–ª–æ–∫–∏, —Ä–µ–ø–ª–∏–∫–∞—Ü–∏—è, –æ—Ç–∫–∞–∑–æ—É—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å.

### üõ† –ü—Ä–∞–∫—Ç–∏–∫–∞ (Lab 1)
- **–°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏:** `hdfs dfs -mkdir -p /user/myself`
- **–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞:** `echo "Hello" > /tmp/test.txt && hdfs dfs -put /tmp/test.txt /user/myself/`
- **–ü—Ä–æ—Å–º–æ—Ç—Ä:** `hdfs dfs -ls /user/myself/`
- **–ß—Ç–µ–Ω–∏–µ:** `hdfs dfs -cat /user/myself/test.txt`

---

## ‚úÖ –ú–æ–¥—É–ª—å 2: MapReduce –∏ YARN
**–¶–µ–ª—å:** –ü–æ–Ω—è—Ç—å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫—É—é –º–æ–¥–µ–ª—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–∞–º–∏.

### üìö –¢–µ–æ—Ä–∏—è
- Map (–†–∞–∑–±–∏–µ–Ω–∏–µ) -> Shuffle (–°–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞) -> Reduce (–ê–≥—Ä–µ–≥–∞—Ü–∏—è).
- YARN: ResourceManager (–ü–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫) –∏ NodeManager (–ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å).

### üõ† –ü—Ä–∞–∫—Ç–∏–∫–∞ (Lab 2: WordCount)
–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –Ω–∞ Java:
```bash
# 1. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
docker exec namenode bash -c "echo 'Hello Hadoop Hello World' > /tmp/input.txt"
docker exec namenode hdfs dfs -put /tmp/input.txt /user/input/

# 2. –ó–∞–ø—É—Å–∫ MapReduce Job
docker exec resourcemanager yarn jar \
  /opt/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar \
  wordcount /user/input /user/output

# 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
docker exec namenode hdfs dfs -cat /user/output/part-r-00000
```

---

## ‚úÖ –ú–æ–¥—É–ª—å 3: Spark Core –∏ RDD
**–¶–µ–ª—å:** –û—Å–Ω–æ–≤—ã –±—ã—Å—Ç—Ä—ã—Ö —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –≤ –ø–∞–º—è—Ç–∏.

### üìö –¢–µ–æ—Ä–∏—è
- RDD (Resilient Distributed Dataset) ‚Äî –Ω–µ–∏–∑–º–µ–Ω—è–µ–º—ã–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏.
- Transformations (Lazy) vs Actions (Eager).
- Spark Shell (REPL).

### üõ† –ü—Ä–∞–∫—Ç–∏–∫–∞ (Lab 3: RDD API)
–í–Ω—É—Ç—Ä–∏ `spark-shell`:
```scala
// –ß—Ç–µ–Ω–∏–µ —Ñ–∞–π–ª–∞
val lines = sc.textFile("hdfs://namenode:9000/user/input/input.txt")
// –ü–æ–¥—Å—á–µ—Ç —Å–ª–æ–≤ (MapReduce –≤ –æ–¥–Ω—É —Å—Ç—Ä–æ–∫—É)
val counts = lines.flatMap(_.split(" ")).map((_, 1)).reduceByKey(_ + _)
// –í—ã–≤–æ–¥
counts.collect().foreach(println)
```

---

## ‚úÖ –ú–æ–¥—É–ª—å 4: Spark SQL –∏ DataFrames
**–¶–µ–ª—å:** –†–∞–±–æ—Ç–∞ —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (–∫–∞–∫ SQL/Pandas).

### üìö –¢–µ–æ—Ä–∏—è
- DataFrame API –∏ —Å—Ö–µ–º–∞ –¥–∞–Ω–Ω—ã—Ö.
- –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä Catalyst.
- –§–æ—Ä–º–∞—Ç Parquet (–∫–æ–ª–æ–Ω–æ—á–Ω–æ–µ —Ö—Ä–∞–Ω–µ–Ω–∏–µ).

### üõ† –ü—Ä–∞–∫—Ç–∏–∫–∞ (Lab 4: NYC Taxi Analysis)
–†–∞–±–æ—Ç–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (Yellow Taxi Trip Data):
```scala
// 1. –ß—Ç–µ–Ω–∏–µ Parquet
val df = spark.read.parquet("hdfs://namenode:9000/user/myself/yellow_tripdata_2023-01.parquet")

// 2. –ò–∑—É—á–µ–Ω–∏–µ —Å—Ö–µ–º—ã
df.printSchema()

// 3. SQL –ê–Ω–∞–ª–∏—Ç–∏–∫–∞ (–°—Ä–µ–¥–Ω–∏–π —á–µ–∫ –ø–æ –∫–æ–ª-–≤—É –ø–∞—Å—Å–∞–∂–∏—Ä–æ–≤)
df.createOrReplaceTempView("trips")
spark.sql("""
  SELECT passenger_count, AVG(total_amount) as avg_fare, COUNT(*) as trips
  FROM trips
  GROUP BY passenger_count
  ORDER BY avg_fare DESC
""").show()
```

---

## üöÄ –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏ (–ü—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å)

### üîú –ú–æ–¥—É–ª—å 5: Spark Streaming
–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
- –ß—Ç–µ–Ω–∏–µ –ø–æ—Ç–æ–∫–∞ –∏–∑ Kafka (–º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å Kafka –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä).
- Structured Streaming API.

### üîú –ú–æ–¥—É–ª—å 6: –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏ –¢—é–Ω–∏–Ω–≥
- Partitioning –∏ Bucketing.
- –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ (`.cache()` / `.persist()`).
- –ü–æ–Ω–∏–º–∞–Ω–∏–µ Spark UI (DAG Visualization).

### üîú –ú–æ–¥—É–ª—å 7: –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ BI (Business Intelligence)
- –ó–∞–ø—É—Å–∫ Spark Thrift Server.
- –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ Tableau, PowerBI –∏–ª–∏ DBeaver –ø–æ JDBC.
